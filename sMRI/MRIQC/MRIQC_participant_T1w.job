#!/bin/bash
# ------------------------------------------------------------------------------
# Script to run MRIQC for quality control of MRI data in a BIDS-compliant dataset.
# The script processes T1-weighted images for multiple participants using Singularity.
#
# Steps:
# 1. Load the Singularity module.
# 2. Define the BIDS-formatted directory containing raw MRI data.
# 3. Use MRIQC to analyze the T1-weighted data for each participant in parallel.
#
# Parameters:
# - `--job-name`: Sets the name of the job for monitoring in Slurm (`MRIQC`).
# - `--partition`: Specifies the queue/partition for scheduling (`bme_cpu`).
# - `--time`: Allocates a maximum runtime of 10 hours.
# - `--cpus-per-task`: Assigns 8 CPU cores for each task.
# - `--mem`: Allocates 8 GB of memory per task.
# - `--array`: Specifies the range of participants to process (0-135).
# - `--mail-user`: Email address for job notifications (set appropriately).
# - `--mail-type`: Specifies when to send job status emails (begin, end, fail, etc.).
#
# Output:
# - Quality control reports for T1-weighted images stored in the `mriqc_t1w` directory.
#
# Notes:
# - Ensure the MRIQC Singularity image (`mriqc-0.16.1.sif`) is present in the specified directory.
# - Adjust the `--array` parameter to match the number of participants.
# - Modify memory and CPU allocation based on system and dataset requirements.
# ------------------------------------------------------------------------------

#SBATCH --job-name=MRIQC                   # Job name
#SBATCH --partition=bme_cpu                # Partition/queue for the job
#SBATCH --time=10:00:00                    # Maximum runtime (10 hours)
#SBATCH --cpus-per-task=8                  # Number of CPU cores per task
#SBATCH --mail-user=""                     # Email for job notifications (update as needed)
#SBATCH --mail-type=BEGIN,END,FAIL,ARRAY_TASKS  # Email notifications for job states
#SBATCH --mem=8g                           # Memory allocation (8 GB per task)
#SBATCH --array=0-135                      # Job array index range for participants

# Load Singularity module for running containerized applications
module load apps/7/singularity/3.5.2       # Load Singularity version 3.5.2

# Define the base directory for the BIDS-compliant dataset
export bidsdir=$HOME/BIDS_Data             # Path to BIDS-formatted data directory

# Navigate to the directory containing BIDS data
cd $HOME/BIDS_Data
participant=(sub-*)                        # Create an array of participant directories (e.g., sub-001, sub-002)

# Navigate to the directory containing the MRIQC Singularity image
cd $HOME/MRIQC/

# Execute the MRIQC command using Singularity
singularity run mriqc-0.16.1.sif \         # Path to the MRIQC Singularity image
    ${bidsdir} \                           # Input: BIDS directory with raw MRI data
    ${bidsdir}/derivatives/mriqc_t1w \     # Output: Directory for quality control reports
    participant \                          # Processing mode (`participant` level analysis)
    --participant-label ${participant[$SLURM_ARRAY_TASK_ID]} \  # Current participant ID
    --verbose-reports \                    # Generate detailed reports
    --n_procs 16 \                         # Use 16 processing threads
    --ants-nthreads 8 \                    # Allocate 8 threads for ANTs
    -m T1w \                               # Specify the modality (T1-weighted images)
    -f \                                   # Force overwrite of existing outputs
    --mem_gb 64000                         # Allocate 64 GB of memory
